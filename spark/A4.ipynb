{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as pys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "\n",
    "#spark_session = SparkSession.builder.master(\"spark://192.168.1.8:7077\").getOrCreate()\n",
    "\n",
    "#sparkC = spark_session.sparkContext\n",
    "sparkC = pys.SparkContext()\n",
    "\n",
    "file_en = sparkC.textFile(\"/home/ubuntu/europarl-v7.sv-en.en\")\n",
    "file_en.cache()\n",
    "file_sv = sparkC.textFile(\"/home/ubuntu/europarl-v7.sv-en.sv\")\n",
    "file_sv.cache()\n",
    "\n",
    "def swap_key_values(tf):\n",
    "        return tf.map(lambda tf: (tf[1], tf[0]))\n",
    "\n",
    "def convert_case(tf):\n",
    "        return tf.map(lambda x: x.lower())\n",
    "\n",
    "# Convert To Lower Case\n",
    "file_en = convert_case(file_en)\n",
    "file_sv = convert_case(file_sv)\n",
    "\n",
    "# Zipping\n",
    "file_en = file_en.zipWithIndex()\n",
    "file_sv = file_sv.zipWithIndex()\n",
    "\n",
    "# Swap Key Values\n",
    "file_en = swap_key_values(file_en)\n",
    "file_sv = swap_key_values(file_sv)\n",
    "\n",
    "# Merging\n",
    "file_merged = file_en.join(file_sv)\n",
    "file_merged = file_merged.sortBy(lambda a: a[0])\n",
    "\n",
    "# Same No of Words\n",
    "smow = file_merged.filter(lambda x: len(x[1][0].split())==len(x[1][1].split()))\n",
    "\n",
    "lines_en = smow.map(lambda a: a[1][0])\n",
    "lines_sv = smow.map(lambda a: a[1][1])\n",
    "\n",
    "tokens_lines_en = lines_en.map(lambda a: a.split())\n",
    "tokens_lines_sv = lines_sv.map(lambda a: a.split())\n",
    "\n",
    "# Construct Token Tuples\n",
    "tokenTuple = tokens_lines_en.zip(tokens_lines_sv)\n",
    "\n",
    "# Construct Word Pair Tuples\n",
    "wordpairTuple = tokenTuple.map(lambda a: list(zip(a[0],a[1])))\n",
    "\n",
    "# Word Pair Fequency Flat Map\n",
    "wordPairFrequencies = wordpairTuple.flatMap(lambda line: line).map(lambda word_pair: (word_pair, 1)).reduceByKey(lambda a, b: a + b).sortBy(lambda a: -a[1])\n",
    "\n",
    "# 20 Values of Word Pair Frequencies From The Top\n",
    "wordPairFrequencies.take(20)\n",
    "wordPairFrequencies.saveAsTextFile(\"/home/ubuntu/result\")\n",
    "sparkC.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
